{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 4"
      ],
      "metadata": {
        "id": "ucxGNyGI_vs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Exploratory Analysis\n",
        "\n",
        "Use the following code to download the dataset from\n",
        "[https://www.kaggle.com/code/mineshjethva/eda-pulsedb/notebook](https://www.kaggle.com/code/mineshjethva/eda-pulsedb/notebook). The dataset is described in the paper [https://doi.org/10.3389/fdgth.2022.1090854](https://doi.org/10.3389/fdgth.2022.1090854).\n",
        "\n",
        "I would recommend saving the data files to a google drive (or your local machine) so that you don't have to download them again. Note that the 5 data files correspond to the 5 columns in Table 4 of the paper.\n"
      ],
      "metadata": {
        "id": "nWcBGhqY_a1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4AP1y_pxclv"
      },
      "outputs": [],
      "source": [
        "# download the data from kagglehub\n",
        "# The dataset is 17.3 G\n",
        "# This took about 15min using university wifi and, if\n",
        "# you save the data, you should only have to do it once\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"weinanwangrutgers/pulsedb-balanced-training-and-testing\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this block to move the data to a permanent directory in your drive\n",
        "\n",
        "import os, glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/pulsedb/\"\n",
        "!mkdir -p $DATA_DIR\n",
        "!cp -r $path/* $DATA_DIR"
      ],
      "metadata": {
        "id": "RnU6-XNKBpoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this block after data is saved to your drive\n",
        "\n",
        "import os, glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/pulsedb/\"\n",
        "\n",
        "mat_files = sorted(glob.glob(os.path.join(DATA_DIR, \"**\", \"*.mat\"), recursive=True))\n",
        "print(f\"Found {len(mat_files)} .mat files\")\n",
        "for f in mat_files:\n",
        "    print(\" -\", f)"
      ],
      "metadata": {
        "id": "Cb3z3VM-xd1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll load the data. The data is about 20GB, which exceeds the colab basic RAM allocation. You can check your RAM using\n",
        "\n",
        "`!cat /proc/meminfo`\n",
        "\n",
        "You should upgrade to colab pro, which is free for students.\n",
        "\n",
        "[https://colab.research.google.com/signup](https://colab.research.google.com/signup)\n",
        "\n",
        "Then in 'change runtime type' click A100 GPU and high RAM."
      ],
      "metadata": {
        "id": "fybIsP4zmCeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "# the subject information is stored in a pandas df\n",
        "# the Signals (ECG, PPG, ABP) are stored in numpy arrays\n",
        "# this block takes 11 minutes to execute\n",
        "\n",
        "!cat /proc/meminfo\n",
        "\n",
        "!pip install mat73\n",
        "import mat73\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_mat_file(file_path):\n",
        "    data_dict = mat73.loadmat(file_path)['Subset']\n",
        "    print('finished loading'+file_path)\n",
        "    # print(data_dict.keys())\n",
        "\n",
        "    # first handle Signals\n",
        "    ECG = data_dict['Signals'][:,0,:]\n",
        "    PPG = data_dict['Signals'][:,1,:]\n",
        "    ABP = data_dict['Signals'][:,2,:]\n",
        "    data_dict.pop(\"Signals\", None)\n",
        "\n",
        "    data_dict['Age'] = data_dict['Age'].tolist()\n",
        "    data_dict['BMI'] = data_dict['BMI'].tolist()\n",
        "    data_dict['DBP'] = data_dict['DBP'].tolist()\n",
        "    data_dict['Gender'] = [1 if x[0] == 'M' else 0 for x in data_dict['Gender']]\n",
        "    data_dict['Height'] = data_dict['Height'].tolist()\n",
        "    data_dict['SBP'] = data_dict['SBP'].tolist()\n",
        "    data_dict['Subject'] = [x[0] for x in data_dict['Subject']]\n",
        "    data_dict['Weight'] = data_dict['Weight'].tolist()\n",
        "\n",
        "    data_df = pd.DataFrame(data_dict)\n",
        "    print('constructed df')\n",
        "\n",
        "    return data_df, ECG, PPG, ABP\n",
        "\n",
        "df_CalBased_Test, ECG_CalBased_Test, PPG_CalBased_Test, ABP_CalBased_Test = load_mat_file(DATA_DIR+'VitalDB_CalBased_Test_Subset.mat')\n",
        "df_Train, ECG_Train, PPG_Train, ABP_Train = load_mat_file(DATA_DIR+'VitalDB_Train_Subset.mat')"
      ],
      "metadata": {
        "id": "pSQFg0mK8cgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_CalBased_Test has 51720 entries\n",
        "print(df_CalBased_Test.keys())\n",
        "print(df_CalBased_Test.info())\n",
        "print(df_CalBased_Test.describe())\n",
        "df_CalBased_Test"
      ],
      "metadata": {
        "id": "GfBz5kcvEPRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1293 subjects, 40 samples/ subject = 51720 samples\n",
        "df_CalBased_Test['Subject'].value_counts()"
      ],
      "metadata": {
        "id": "xP89OfDQEqwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "jIc-z3zuJWlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Blood Pressure Prediction\n"
      ],
      "metadata": {
        "id": "rhZ5XU2rIpLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "Bl2N87kvImVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Generative Modeling"
      ],
      "metadata": {
        "id": "l0Qg1Sm8JP2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "dEoQzvV4JPFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}